{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('temp', 'rb') as f:\n",
    "#     tweets_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \"\"\"\n/usr/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('brand-classifier.csv', encoding='latin1')\n",
    "work_data = df[['description', 'gender']]\n",
    "work_data['filtered'] = work_data.gender.apply(\n",
    "    lambda x: 1 if x == 'brand' else 0)\n",
    "work_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gender  filtered\n0        male         0\n1        male         0\n2        male         0\n3        male         0\n4      female         0\n5      female         0\n6       brand         1\n7        male         0\n8      female         0\n9      female         0\n10      brand         1\n11      brand         1\n12     female         0\n13      brand         1\n14     female         0\n16     female         0\n17       male         0\n20     female         0\n21     female         0\n22     female         0\n23       male         0\n24       male         0\n25     female         0\n26      brand         1\n27      brand         1\n28     female         0\n29       male         0\n30      brand         1\n31       male         0\n32     female         0\n...       ...       ...\n20016  female         0\n20018    male         0\n20019    male         0\n20020   brand         1\n20021    male         0\n20022    male         0\n20024   brand         1\n20025   brand         1\n20026    male         0\n20028  female         0\n20029   brand         1\n20030   brand         1\n20032    male         0\n20033  female         0\n20034   brand         1\n20035  female         0\n20036  female         0\n20037    male         0\n20038   brand         1\n20039  female         0\n20040    male         0\n20041   brand         1\n20042   brand         1\n20043    male         0\n20044  female         0\n20045  female         0\n20046    male         0\n20047    male         0\n20048  female         0\n20049  female         0\n\n[16224 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(work_data[['gender', 'filtered']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk as nlp\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemma = nlp.WordNetLemmatizer()\n",
    "text = []\n",
    "for each in data.description:\n",
    "    each = re.sub(\"[^a-zA-Z]\", \" \", str(each))\n",
    "    # lowercase all\n",
    "    each = each.lower()\n",
    "    # split all by tokenizing\n",
    "    each = nlp.word_tokenize(each)\n",
    "    # delete stop words from your array\n",
    "    each = [word for word in each if not word in set(\n",
    "        stopwords.words(\"english\"))]\n",
    "    # lemmatize \"memories\" -> \"memory\"\n",
    "    each = [lemma.lemmatize(word) for word in each]\n",
    "    each = \" \".join(each)\n",
    "    # put them into big array\n",
    "    text.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countVectorizer = CountVectorizer(stop_words='english', max_features=500)\n",
    "mat = countVectorizer.fit_transform(text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12979\n"
     ]
    }
   ],
   "source": [
    "y = work_data.filtered\n",
    "x = mat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x,y,test_size=0.2)\n",
    "print(len(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7158705701078583\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "c = MultinomialNB()\n",
    "c.fit(train_x, train_y)\n",
    "\n",
    "print(c.score(test_x, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
