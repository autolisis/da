{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target' 'id' 'date' 'flag' 'user' 'text']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('tweets.csv', encoding='latin1')\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['text'] = df.text\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000\n@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets))\n",
    "print(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk as nlp\n",
    "# import re\n",
    "# from nltk.corpus import stopwords\n",
    "# \n",
    "# lemma = nlp.WordNetLemmatizer()\n",
    "# text = []\n",
    "# for each in data.text:\n",
    "#     each = re.sub(\"[^a-zA-Z]\", \" \", str(each))\n",
    "#     # lowercase all\n",
    "#     each = each.lower()\n",
    "#     # split all by tokenizing\n",
    "#     each = nlp.word_tokenize(each)\n",
    "#     # delete stop words from your array\n",
    "#     each = [word for word in each if not word in set(\n",
    "#         stopwords.words(\"english\"))]\n",
    "#     # lemmatize \"memories\" -> \"memory\"\n",
    "#     each = [lemma.lemmatize(word) for word in each]\n",
    "# #     # put them into big array\n",
    "#     text.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('tweets-lemma.txt', 'wb') as f:\n",
    "#     pickle.dump(text, f)\n",
    "with open('tweets-lemma.txt', 'rb') as f:\n",
    "    text = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "# model = Word2Vec(text, min_count=2)\n",
    "# model.wv.save_word2vec_format('word2vec-tweets')\n",
    "model = KeyedVectors.load_word2vec_format('word2vec-tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sister', 0.841433048248291), ('cousin', 0.7108091115951538), ('bro', 0.6551007628440857), ('bros', 0.6453346610069275), ('dad', 0.6419702768325806), ('nephew', 0.637410581111908), ('maggiex', 0.6359193921089172), ('brothes', 0.6213483214378357), ('limor', 0.6047430634498596), ('victoriax', 0.5994175672531128)]\n"
     ]
    }
   ],
   "source": [
    "print(model.similar_by_word('brother'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model.syn0\n",
    "n_words = word_vectors.shape[0]\n",
    "vector_size = word_vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_jobs=4, random_state=0)\n",
    "idx = kmeans.fit_predict(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_centroid_list = list(zip(model.index2word, idx))\n",
    "word_centroid_list_sort = sorted(word_centroid_list, key=lambda el: el[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = {}\n",
    "file_out = open('cluster-output', \"w\")\n",
    "file_out.write(\"WORD\\tCLUSTER_ID\\n\")\n",
    "for word_centroid in word_centroid_list_sort:\n",
    "    line = word_centroid[0] + '\\t' + str(word_centroid[1]) + '\\n'\n",
    "    cluster[word_centroid[0]] = word_centroid[1]\n",
    "    file_out.write(line)\n",
    "file_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee 6\ntea 6\nwater 7\ngood 3\nbad 3\nbeautiful 9\nugly 7\npen 7\nchocolate 6\nfood 6\npizza 6\nhungry 6\ncompany 0\nwater 7\nrain 9\nhurricane 1\nbrother 4\nsister 3\nfather 3\nniece 9\nschool 9\ncollege 9\nuniversity 9\n"
     ]
    }
   ],
   "source": [
    "# See if there's any semantic meaning captured in the clustering\n",
    "words = ['coffee', 'tea', 'water','good', 'bad',\n",
    "         'beautiful', 'ugly', 'pen', 'chocolate',\n",
    "         'food', 'pizza', 'hungry', 'company', 'water', 'rain',\n",
    "         'hurricane', 'brother', 'sister', 'father', 'niece',\n",
    "         'school', 'college', 'university']\n",
    "for word in words:\n",
    "    print(word, cluster[word])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
